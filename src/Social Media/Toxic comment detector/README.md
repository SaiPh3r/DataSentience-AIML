# 🧠 Toxic Comment Detector

A multi-label NLP classifier that detects toxic behavior in user-generated comments. Built using the [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) dataset, this project flags toxic, threatening, and obscene language to improve online community safety.

[!ui screenshot](assets/image.png)
---

## 🔍 Features

- ✅ Multi-label classification (`toxic`, `obscene`, `threat`, `insult`, etc.)
- ✅ TF-IDF vectorization + Logistic Regression baseline
- ✅ Modular code for training and prediction
- ✅ Easy extension to transformer models (e.g., BERT)
- ✅ Clean CLI-based interface for demo testing

---


